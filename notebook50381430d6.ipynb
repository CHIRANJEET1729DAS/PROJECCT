{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":7875505,"sourceType":"datasetVersion","datasetId":4621651}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNNBlock(nn.Module):\n    def __init__ (self, in_channels,out_channels,stride):\n        super().__init__()\n        self.conv=nn.Sequential(\n             nn.Conv2d(in_channels,out_channels,4,stride,bias=False,padding_mode=\"reflect\"),\n             nn.BatchNorm2d(out_channels),\n             nn.LeakyReLU(0.2),\n        )\n        \n    def forward(self,x):\n        return self.conv(x)\nclass Discriminator (nn.Module):\n    def __init__(self,in_channels=3,features=[64,128,256,512]):\n        super().__init__()\n        self.initial = nn.Sequential(\n        nn.Conv2d(in_channels*2,features[0],kernel_size=4,stride=2,padding=1,padding_mode=\"reflect\"),\n        nn.LeakyReLU(0.2),\n        )\n        layers=[]\n        in_channels = features[0]\n        for feature in features[1:]:\n            layers.append(\n            CNNBlock(in_channels,feature,stride=1 if feature  == features[-1] else 2),\n            )\n            in_channels = feature\n        layers.append(nn.Conv2d(in_channels,1,kernel_size=4,stride=1,padding=1,padding_mode=\"reflect\"))\n        self.model = nn.Sequential (*layers)\n    def forward(self,x,y):\n        x=torch.cat([x,y],dim=1)\n        x=self.initial(x)\n        return self.model(x)\n\ndef test():\n    x= torch.randn((1,3,286,286))\n    y = torch.randn((1,3,286,286))\n    model = Discriminator()\n    preds = model(x,y)\n    print(preds.shape) \n    \nif __name__ =='__main__':\n    test()\n    ","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n            if down\n            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n        )\n        self.use_dropout = use_dropout\n        self.dropout = nn.Dropout(0.5)\n        \n    def forward(self, x):\n        x = self.conv(x)\n        return self.dropout(x) if self.use_dropout else x\n\n\nclass Generator(nn.Module):\n    def __init__(self, in_channels=3, features=64):\n        super().__init__()\n        self.initial_down = nn.Sequential(\n            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n            nn.LeakyReLU(0.2),\n        )\n        self.down1 = Block(features, features*2, down=True, act=\"leaky\", use_dropout=False)\n        self.down2 = Block(features*2, features*4, down=True, act=\"leaky\", use_dropout=False)\n        self.down3 = Block(features*4, features*8, down=True, act=\"leaky\", use_dropout=False)\n        self.down4 = Block(features*8, features*8, down=True, act=\"leaky\", use_dropout=False)\n        self.down5 = Block(features*8, features*8, down=True, act=\"leaky\", use_dropout=False)\n        self.down6 = Block(features*8, features*8, down=True, act=\"leaky\",use_dropout=False)\n        self.bottleneck = nn.Sequential(\n            nn.Conv2d(features*8, features*8, 4, 2, 1, padding_mode=\"reflect\"),\n            nn.ReLU()\n        )\n        self.up1 = Block(features*8, features*8, down=False, act=\"relu\", use_dropout=True)\n        self.up2 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=True)\n        self.up3 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=True)\n        self.up4 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=True)\n        self.up5 = Block(features*8*2, features*4, down=False, act=\"relu\", use_dropout=True)\n        self.up6 = Block(features*4*2, features*2, down=False, act=\"relu\", use_dropout=True)\n        self.up7 = Block(features*2*2, features, down=False, act=\"relu\", use_dropout=True)\n        self.final_up = nn.Sequential(\n            nn.ConvTranspose2d(features*2, in_channels, kernel_size=4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n        \n    def forward(self, x):\n        d1 = self.initial_down(x)\n        d2 = self.down1(d1)\n        d3 = self.down2(d2)\n        d4 = self.down3(d3)\n        d5 = self.down4(d4)\n        d6 = self.down5(d5)\n        d7 = self.down6(d6)\n        bottleneck = self.bottleneck(d7)\n        up1 = self.up1(bottleneck)\n        up2 = self.up2(torch.cat([up1, d7], 1))\n        up3 = self.up3(torch.cat([up2, d6], 1))\n        up4 = self.up4(torch.cat([up3, d5], 1))\n        up5 = self.up5(torch.cat([up4, d4], 1))\n        up6 = self.up6(torch.cat([up5, d3], 1))\n        up7 = self.up7(torch.cat([up6, d2], 1))\n        return self.final_up(torch.cat([up7,d1],1))\n\n\ndef test():\n    x = torch.randn((32, 3, 256, 256))\n    model = Generator(in_channels=3, features=64)\n    pred = model(x)\n    print(pred.shape)\n\nif __name__ == \"__main__\":\n    test()\n","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport glob\nimport os\n\nimage_paths = glob.glob(os.path.join('/kaggle/input/picstopics/PICStoPICS/maps/train/train', '*.jpg'))\n\noutput_dir = '/kaggle/input/picstopics/PICStoPICS/maps/train'\n\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\n\nfor image_path in image_paths:\n\n    image = cv2.imread(image_path)\n\n    height, width, _ = image.shape\n    half_width = width // 2\n\n    data_roi = image[:, :half_width]\n    label_roi = image[:, half_width:]\n\n    data_dir = os.path.join(output_dir, 'data')\n    label_dir = os.path.join(output_dir, 'labels')\n\n    if not os.path.exists(data_dir):\n        os.makedirs(data_dir)\n    if not os.path.exists(label_dir):\n        os.makedirs(label_dir)\n\n    data_roi_path = os.path.join(data_dir, os.path.basename(image_path))\n    label_roi_path = os.path.join(label_dir, os.path.basename(image_path))\n    cv2.imwrite(data_roi_path, data_roi)\n    cv2.imwrite(label_roi_path, label_roi)\n\n\n","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nclass DataLabelDataset(Dataset):\n    def __init__(self, data_dir_data, data_dir_labels, transform=None):\n        self.data_dir_data = data_dir_data\n        self.data_dir_labels = data_dir_labels\n        self.data_files = os.listdir(data_dir_data)\n        self.label_files = os.listdir(data_dir_labels)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data_files)\n\n    def __getitem__(self, idx):\n        data_img_name = os.path.join(self.data_dir_data, self.data_files[idx])\n        label_img_name = os.path.join(self.data_dir_labels, self.label_files[idx])\n\n        data_image = Image.open(data_img_name)\n        label_image = Image.open(label_img_name)\n\n        if self.transform:\n            data_image = self.transform(data_image)\n            label_image = self.transform(label_image)\n\n        return data_image, label_image\n\ndata_dir_data = '/kaggle/input/picstopics/PICStoPICS/maps/train/data'\ndata_dir_labels = '/kaggle/input/picstopics/PICStoPICS/maps/train/labels'\n\ntransform = transforms.Compose([\n    transforms.ToTensor(), transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]),transforms.Resize((256, 256))\n])\n\n\ndata_label_dataset = DataLabelDataset(data_dir_data, data_dir_labels, transform=transform)\n\ntrain_loader = DataLoader(data_label_dataset, batch_size=32, shuffle=True,drop_last=True)\n\nfor x, y in train_loader:\n    print(x.shape,y.shape)\n    break\n    \n\n","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef train():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    disc = Discriminator(in_channels=3).to(device)\n    gen = Generator(in_channels=3, features=64).to(device)\n    optim_disc = torch.optim.Adam(disc.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    optim_gen = torch.optim.Adam(gen.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    Disc_loss_final = []\n    Gen_loss_final = []\n    predicted_images = []\n    BCE = nn.BCEWithLogitsLoss()\n    L1_LOSS = nn.L1Loss()\n    epochs = 300\n\n    for epochi in range(epochs):\n        for data, map_data in train_loader:\n            data, map_data = data.to(device), map_data.to(device)\n\n            # Train Discriminator\n            Disc_losses = []\n            x = torch.randn((32, 3, 256, 256)).to(device)\n            pred_images = gen(x)\n            pred_real_disc = disc(data, map_data)\n            pred_fake_disc = disc(data, pred_images.detach())\n            real_loss_disc = BCE(pred_real_disc, torch.ones_like(pred_real_disc))\n            fake_loss_disc = BCE(pred_fake_disc, torch.zeros_like(pred_fake_disc))\n            Disc_loss = (real_loss_disc + fake_loss_disc) / 2\n            Disc_losses.append(Disc_loss.item())\n            optim_disc.zero_grad()\n            Disc_loss.backward()\n            optim_disc.step()\n\n            # Train Generator\n            Gen_loss = []\n            pred_fake_disc = disc(data, pred_images.detach())\n            gen_fake_loss = BCE(pred_fake_disc, torch.ones_like(pred_fake_disc))\n            l1 = L1_LOSS(pred_images, map_data)\n            gen_loss = gen_fake_loss + l1\n            Gen_loss.append(gen_loss.item())\n            optim_gen.zero_grad()\n            gen_loss.backward()\n            optim_gen.step()\n\n        Disc_loss_final.append(torch.mean(torch.tensor(Disc_losses)))\n        Gen_loss_final.append(torch.mean(torch.tensor(Gen_loss)))\n\n        if (epochi + 1) % 2 == 0:\n            print(f'Finished epoch {epochi+1}/{epochs}')\n            \n    # Assuming you have a DataLoader instance for validation/test\n    x, y = next(iter(train_loader))\n    x, y = x.to(device), y.to(device)\n    predicted_images.append(gen(x).detach().cpu())  # Move to CPU for storage\n\n    return Disc_loss_final, Gen_loss_final, disc, gen, predicted_images\n","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nDisc_loss, Gen_loss, disc, gen, predicted_images = train()\n\n\n\n\n\n\n\n\n","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nDisc_loss = [torch.tensor([loss]).cpu().item() for loss in Disc_loss]\nGen_loss = [torch.tensor([loss]).cpu().item() for loss in Gen_loss]\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\nax[0].plot(Disc_loss, 'r^-')\nax[0].set_title('Discriminator Loss')\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Loss')\n\nax[1].plot(Gen_loss, 'g*-')\nax[1].set_title('Generator Loss')\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Loss')\nplt.show()\n\n\nnum_images_to_display = min(4, len(predicted_images))  \nfig, axes = plt.subplots(1, num_images_to_display, figsize=(15, 5))\n\n# Handle case when num_images_to_display is 1\nif num_images_to_display == 1:\n    axes = [axes]\n\nfor i in range(num_images_to_display):\n    axes[i].imshow(predicted_images[i][0].permute(1, 2, 0).cpu()) \n    axes[i].axis('off')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}